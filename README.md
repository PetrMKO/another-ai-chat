# Another AI Chat

Плагин для интеграции LLM моделей в [Figma](https://qdrant.tech/)
****

## Серверное приложение
Бекенд реализован на [Python](https://www.python.org/) и [FastApi](https://fastapi.tiangolo.com/).
Для хранения векторных данных (чанков) используется [qdrant](https://qdrant.tech/)
Для хранения остальных данных используется [PostgreSQL](https://www.postgresql.org/)

Для запуска серверного приложения необходим [Docker](https://www.docker.com/)

После клонирования проекта необходимо выполнить команду
```shell

cd backend
docker compose up
```

После выполнения поднимется инстанс Postgres, qdrant и само серверное приложение
****

## Клиентское приложение
Сам плагин реализован на [React](https://react.dev/). Для сборки используется [vite](https://vite.dev/)

Для добавления плагина в Figma необходимо создать новый плагин и внести изменения в [манифест](/client/figma.manifest.ts) внеся новый id.
После нужно собрать проект, должна быть установлена [node.js](https://nodejs.org)
```shell

cd client
npm install
npm run build
```

Для разработки вместо build
```shell

npm run dev
```

****
## Авторизация
В клиенте реализована авторизация созданием id. При первом входе в плагин пользователю создается идентификатор и запоминается в Figma. Далее этот id используется для хранения пользовательской информации
****

## Настройки чата
**Количество сообщений в контексте** - Настройка отвечающая за количество сообщений в чате  
**Системное сообщение** - позиционирование чат бота  
**Файл контекста** - файл используемый для RAG. Поддерживается только txt
****

## Настройки конфигураций
В плагин интегрировано несколько возможных конфигураций, для использования LLM

### VseGPT
Используется агрегатор [vsegpt](https://vsegpt.ru/)  

Для использования нужен ключ API сервиса
Настройки: 
- **API ключ** - API ключ аккаунта на vsegpt
- **Модель** - LLM модель, доступная в агрегатор

### X5 CoPilot
Интеграция моделей от X5, для уточнения обращаться к ответственному лицу

### Своя конфигурация
Плагин также поддерживает использование любого OpenAI like API. Для этого достаточно указать:
 - **URL** - url сервиса, которые хотите использовать (/chat/completions добавится на стороне сервера)
 - **API Ключ** - API ключ от сервиса. Можно оставить пустым, если, например, сервис локальный
 - **Название модели** - название модели сервиса

